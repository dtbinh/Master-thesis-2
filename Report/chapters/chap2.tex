\chapter{Repetitive Learning Model Predictive Control}
This chapter gives a general introduction to the concept of Model Predictive Control (MPC). Based on that, the theory of Learning Model Predictive Control (LMPC) for repetitive tasks is presented. %Additionally, simulations of LTI systems are performed and analyzed to verify its practicability.

\section{Model Predictive Control}
Model Predictive Control is a concept that has been developed since the late 1970s, starting from Chemical Process Industries \cite{garcia1989model}. Since then, increasing computational power  has helped further research on this method and has extended it to other fields beyond chemical industries.
%One strong advantage of MPC is its ability to include state and input constraints 
This section gives a brief overview of the mathematical concepts of MPC \cite{Borrelli2003}.\\
Given the discrete time system
\begin{equation}\label{eq:systemDynamics}
\bm{x}_{t+1}=f(\bm{x}_t,\bm{u}_t),
\end{equation}
where $\bm{x}\in \mathbb{R}^n$ and $\bm{u}\in\mathbb{R}^m$ are the system state and input, subject to the constraints
\begin{equation}
\bm{x}_t\in\mathcal{X},\ \bm{u}_t\in\mathcal{U},\ \forall t\in\mathbb{Z}_{0+}.
\end{equation}
The MPC controller tries to minimize the following \emph{objective function},
\begin{equation}
J_{t\rightarrow t+N}(\bm{x}_t,\bm{u}_{t\rightarrow t+N-1})=\sum_{k=t}^{t+N-1}h(\bm{x}_{k|t},\bm{u}_{k|t}) + p(\bm{x}_{t+N|t}),
\end{equation}
where $N$ is the time horizon. The terms $h(\bm{x}_k,\bm{u}_k)$ and $p(\bm{x}_N)$ are referred to as \emph{stage cost} and \emph{terminal cost}, respectively. 
%{\bfseries{If you wanna be formal look Borrelli's book or the paper about LMPC, you need to define the optimal trajectory at time $t$ and then that you apply just the first input of that trajectory.}}
Then, at each time step $t$, the objective function is minimized and its first optimal input $\bm{u}_{t|t}^*$ is applied to the system. This results in a Constrained Finite Time Optimal Control (CFTOC) problem:
\begin{subequations}\label{eq:generalMPC}
\begin{align}
J_{t\rightarrow t+N}^*(\bm{x}_t,\bm{u}_{t\rightarrow t+N-1})&=\min_{\bm{u}_{t|t},...,\bm{u}_{t+N-1|t}}\left[\sum_{k=t}^{t+N-1}h(\bm{x}_{k|t},\bm{u}_{k|t}) + p(\bm{x}_{t+N|t})\right]\\
\text{s.t.}\notag\\
\bm{x}_{k+1|t}&=f(\bm{x}_{k|t},\bm{u}_{k|t}),\ \forall k\in [t,...,t+N-1]\\
\bm{x}_{t|t}&=\bm{x}_t\\
\bm{x}_{k|t}&\in\mathcal{X},\ \bm{u}_{k|t}\in\mathcal{U},\ \forall k\in [t,...,t+N-1]
\end{align}
\end{subequations}
with the optimal solution for the state $\bm{x}_{t|t\rightarrow t+N|t}^*$ and for the input $\bm{u}_{t|t\rightarrow t+N-1|t}^*$. The first optimal input is applied to the system:
\begin{equation}\label{eq:firstInput}
\bm{u}_t=\bm{u}_{t|t}^*.
\end{equation}
Solving Eq. \eqref{eq:generalMPC} and applying the first optimal input \eqref{eq:firstInput} at every time step results in a \emph{Receding horizon controller (RHC)}.
There are different approaches on how this optimization problem is solved, two common ways are the \emph{Batch Approach} and the \emph{Recursive Approach}. In general, the optimization problem can be non-convex.\\

\section{Learning Model Predictive Control}\label{sec:LMPC}
Learning Model Predictive Control (LMPC) is a novel control strategy that allows finding an optimal trajectory in an iterative task by learning from previous iterations. It is based on the concept of Iterative Learning Control (ILC). In general, ILCs are control strategies 
%{\bfseries{there are many different ILCs}}
aiming to minimize the tracking error of an iterative process by improving its trajectory with every iteration, learning from previous trajectories. It is limited to fixed time processes with given tracking references. \cite{Lee2007}, \cite{Bristow2006} give overviews of existing methods on ILC.\\
LMPC extends the framework of ILC by adding an optimization function which allows finding an optimal trajectory of optimal duration. Applying this strategy makes it possible to gradually find an optimal trajectory for complex nonlinear systems.
%{\bfseries{Again, this under low computational cost is a strong statement, in theory you should solve a Mixed Integer Programming Problem (The relaxation is coming but it is not there yet)}}.{\bfseries{In general if you expect people  to be tough on you then you must be able to motivate every single work that you say/write -> Ok, got it!}}\\
\paragraph{Definition of iterative processes}
There are two types of iterative processes that have to be distinguished: \emph{Batch processes} and \emph{Continuous repetitive processes} \cite{Wang2009}. Batch processes are intermittently run and are usually modeled starting from the same initial state. As opposed to that, continuous repetitive processes transition directly from one iteration to the next one, meaning that the last state of an iteration matches the initial state of the next iteration.
\paragraph{Theory of LMPC}
In general, the control problem consists of an optimization problem which can be written as follows:
\begin{subequations}\label{eq:generalProblem}
\begin{align}
J_{0\rightarrow \infty}^*(\bm{x}_0)&=\min_{\bm{u}_0,\bm{u}_1,\ldots} \sum\limits_{k=0}^{\infty} h(\bm{x}_k,\bm{u}_k)\\
\textrm{s.t. }
&\bm{x}_{k+1}=f(\bm{x}_k,\bm{u}_k),~\forall k\geq 0 \\
&\bm{x}_0 = \bm{x}_S \label{eq:generalProblem3}\\
&\bm{x}_k \in \mathcal{X},~\bm{u}_k \in \mathcal{U},~\forall k\geq 0
\end{align}
\end{subequations}
with $\bm{x}_S$ being the initial state at each iteration.
Following theory has been adapted from \cite{Rosolia2016}.\\
First, we define the stage cost of a state $\bm{x}_t^j$ at time $t$ in iteration $j$ as follows:
\begin{equation}\label{eq:iterationCost}
h(\bm{x}_F,0)=0\text{ and } h(\bm{x}_t^j,\bm{u}_t^j)>0\ \forall\ \bm{x}_t^j\in\mathbb{R}^n\setminus \{\bm{x}_F\},\bm{u}_t^j\in\mathbb{R}^m\setminus\{0\}
\end{equation}
where $\bm{x}_F$ is the final state with $f(\bm{x}_F,0)=0$.
Then, the cost of one iteration $j$ is defined as the sum of its stage costs:
\begin{equation}
J^j = J_{0\rightarrow\infty}^j(\bm{x}_0^j)=\sum_{k=0}^\infty h(\bm{x}_k^j,\bm{u}_k^j).
\end{equation}
Similarly, the cost-to-go of one specific state $\bm{x}_t^j$ of iteration $j$ is defined as
\begin{equation}\label{eq:LMPC_costToGo}
J_{t\rightarrow\infty}^j(\bm{x}_t^j)=\sum_{k=t}^\infty h(\bm{x}_k^j,\bm{u}_k^j).
\end{equation}
LMPC constructs a sampled safe set of feasible trajectories which is used as a terminal state constraint in the MPC formulation:
\begin{equation}
\mathcal{SS}^j = \left\{ \bigcup_{i\in M^j} \bigcup_{t=0}^\infty \bm{x}_t^i\right\}
\end{equation}
where $M^j$ is the set of indexes $k$ associated with successful iterations $k$ for $k \leq j$, defined as
\begin{equation}
M^j=\left\{ k\in [0,j]: \lim_{t\rightarrow\infty}\bm{x}_t^k=\bm{x}_F\right\}.
\end{equation}
Additionally, a terminal cost function is defined over the sampled safe set:
\begin{equation}\label{eq:Qfunction}
Q^j(\bm{x})=\begin{dcases}
\min_{(i,t)\in F^j(\bm{x})} J_{t\rightarrow\infty}^i(\bm{x}),&\text{if }\bm{x}\in\mathcal{SS}^j\\
+\infty,&\text{if } \bm{x}\not\in \mathcal{SS}^j
\end{dcases}
\end{equation}
with
\begin{equation}
F^j(\bm{x})=\left\{(i,t):i\in [0,j],t\geq 0\text{ with }\exists\ \bm{x}_t^i\in\mathcal{SS}^j \text{ and }\bm{x}_t^i=\bm{x}\right\}.
\end{equation}
Using the terminal constraints and terminal cost we can write the finite time constrained optimal control problem:
\begin{subequations}
\begin{align}
J_{t\rightarrow t+N}^{\scalebox{0.4}{LMPC},j}(\bm{x}_t^j)&=\min_{\bm{u}_{t|t},...,\bm{u}_{t+N-1|t}}\left[\sum_{k=t}^{t+N-1}h(\bm{x}_{k|t},\bm{u}_{k|t})+Q^{j-1}(\bm{x}_{t+N|t})\right]\\
\text{s.t.}\notag\\
\bm{x}_{k+1|t}&=f(\bm{x}_{k|t},\bm{u}_{k|t}),\forall k\in[t,...,t+N],\label{eq:LMPCupdate}\\
\bm{x}_{t|t}&=\bm{x}_t^j,\\
\bm{x}_{k|t}&\in\mathcal{X},\bm{u}_{k|t}\in\mathcal{U},\forall k\in[t,...,t+N],\\
\bm{x}_{t+N|t}&\in\mathcal{SS}^{j-1}\label{eq:generalLMPC5}.
\end{align}\label{eq:generalLMPC}
\end{subequations}
Let
\begin{align}
\bm{u}_{t:t+N-1|t}^{*,j}&=[\bm{u}_{t|t}^{*,j},...,\bm{u}_{t+N-1|t}^{*,j}]\\
\bm{x}_{t:t+N|t}^{*,j}&=[\bm{x}_{t|t}^{*,j},...,\bm{x}_{t+N|t}^{*,j}]
\end{align}
be the optimal solution of Eq. \eqref{eq:generalLMPC} at time $t$ of the $j$-th iteration. Then, at time $t$ of iteration $j$, the first element of $\bm{u}_{t:t+N|t}^{*,j}$ is applied to the system \eqref{eq:systemDynamics}
\begin{equation}\label{eq:recHorizon}
\bm{u}_t^j = \bm{u}_{t|t}^{*,j}.
\end{equation}
This is repeated at time $t+1$, based on the new state $\bm{x}_{t+1|t+1}=\bm{x}_{t+1}^j$, yielding a \emph{moving} or \emph{receding horizon} control strategy.\\
It can be shown that this control strategy is recursively feasible and that the equilibrium $\bm{x}_F$ is asymptotically stable for the closed-loop  system \eqref{eq:systemDynamics} and \eqref{eq:generalLMPC}. Additionally, the iteration cost $J^j$ does not increase with the iteration index $j$ and the trajectory converges to a local optimum for $j\rightarrow\infty$.\\
The LMPC strategy presented above applies for batch processes, i.e. the initial state $\bm{x}_0^j=\bm{x}_S$ in Eq. \eqref{eq:generalProblem3} has to be the same for each iteration. However, it is not applicable for continuous repetitive systems, for which the final state of an iteration corresponds to the initial state of the next iteration. The next section shows the extension for the repetitive case.

\section{Repetitive Learning Model Predictive Control}
This section presents a learning control strategy for continuous repetitive systems. We prove recursive feasibility, non-increasing iteration cost, and optimality, using the mathematical tools we introduced in section \ref{sec:LMPC}.\\

\paragraph{Periodicity and switching condition}
%First, we assume that the state dynamics and stage cost are periodic with periodicity vector $\bm{p}$:
%\begin{align}
%f(\bm{x}_k+\bm{p},\bm{u}_k) &= f(\bm{x}_k,\bm{u}_k)+\bm{p}\\
%h(\bm{x}+\bm{p},\bm{u}) &= h(\bm{x},\bm{u}).
%\end{align}
%If the dynamics are periodic in one state, the periodicity is expressed using a standard basis vector $\bm{p}=P\bm{e}_i$, where $P$ is the periodicity in state $i$.\\
%The switching from one iteration to the next one happens when the periodic state reaches $P$, i.e. $\bm{xe}_i^T\geq P$.\\
%{\bfseries{NOTE: In the following you will see what I meant in the previous comment. Basically, first you can give an explanation in words that explains the equation that you wanna to introduce.}}\\
As the initial state depends on the final state of the previous iteration for repetitive systems, it can not be constrained to a single state $\bm{x}_S$ (as in \eqref{eq:generalProblem3}). The problem from Eq. \eqref{eq:generalProblem} therefore needs to be slightly changed:
\begin{subequations}\label{eq:generalNewProblem}
\begin{align}
J_{0\rightarrow \infty}^*(\bm{x}_0)&=\min_{\bm{x}_0,\bm{u}_0,\bm{u}_1,\ldots} \sum\limits_{k=0}^{\infty} h(\bm{x}_k,\bm{u}_k)\\
\textrm{s.t. }
&\bm{x}_{k+1}=f(\bm{x}_k,\bm{u}_k),~\forall k\geq 0 \\
&\bm{x}_0 \in \mathcal{L} \\
&\bm{x}_k \in \mathcal{X},~\bm{u}_k \in \mathcal{U},~\forall k\geq 0
\end{align}
\end{subequations}
% Clean this section!
The set $\mathcal{L}$ contains all feasible initial states.

Continuous repetitive systems are defined by smooth transitions between two iterations. In particular, we have that the final state of iteration $j-1$ becomes the initial state of iteration $j$,
\begin{equation}\label{eq:transCond}
	\bm{x}_0^{j+1}=\bm{x}_{\bar t_j+1}^j-\bm{p}\ \forall j\geq 0,
\end{equation}
with
\begin{equation}
\bar t_j = \argmin_t\{t+1:\bm{x}_{t+1}^j\in\mathcal X_F\}
\end{equation}
being the time of the transition between iteration $j$ and $j+1$.
Eq. \eqref{eq:transCond} guarantees that the state remains within the bounds of one period and does not accumulate. It also allows us to extend the sampled safe set beyond the limit of the period $\bm{p}$.
%This implicates that, at the end of one iteration, the control needs to take the beginning of the next iteration into account in order to find an optimal input.{\bfseries{Yes, but why. I know it and it is easy to understand, but imagine someone that is reading this for the first time and he has seen the LMPC formulation just once in the previous paragraph.}}\\
%We achieve this by creating a safe set that extends beyond the final state of one iteration to the end of the consecutive iteration.
%\assumption{Assumption}
\begin{assumption}\label{as:nonempty}
We assume that $\mathcal{SS}^0$ is a given non-empty set and the trajectory $\bm{x}^0\in\mathcal{SS}^0$ is feasible and convergent to $\mathcal{X}_F$ with $\bm{x}_0^1=\bm{x}_{\bar t_0}^0-\bm{p}$.
\end{assumption}

\begin{remark}
Assumption \ref{as:nonempty} assumes that we can provide a feasible trajectory that reaches the terminal set $\mathcal{X}_F$.
\end{remark}

\begin{assumption}\label{as:nonincLMPC}
At time $t=0$ of the $j$-th iteration we assume that $J_{0\rightarrow N}^{\scalebox{0.4}{LMPC}}(\bm{x}_0^j)\leq J_{0\rightarrow N}^{\scalebox{0.4}{LMPC}}(\bm{x}_0^{j-1}),\ \forall j\geq 1$.
\end{assumption}

\begin{remark}
Assumption \ref{as:nonincLMPC} implies that the LMPC cost in the initial condition does not increase from iteration to iteration. In general, this can not be assumed for all types of systems and is difficult to verify. However, in our application of autonomous racing we expect the car to cross the finish line at higher velocities in each iteration. This would suggest this assumption to hold, which was also confirmed in experiments.
\end{remark}

\begin{theorem}
Consider system \eqref{eq:systemDynamics} controlled by the LMPC \eqref{eq:generalLMPC} and \eqref{eq:recHorizon}. Let $\mathcal{SS}^j$ be the sampled safe set at the $j$-th iteration. Let assumption \ref{as:nonempty} hold, then the LMPC \eqref{eq:generalLMPC} and \eqref{eq:recHorizon} is feasible at $\forall j\geq 1$ and $t\in \mathbb{Z}_{0+}$. Moreover, the closed loop system \eqref{eq:systemDynamics} and \eqref{eq:generalLMPC} converges to the invariant set $\mathcal{X}_F$ at each $j$-th iteration $\forall y\geq 0$.
\end{theorem}
\begin{proof}
% Idea: First check first time step t=0 of first iteration (j=1)
% Then: prove that t+1 is feasible if t is feasible
% Then prove that if \bar t^j is feasible then \bar t+1^j is feasible which is equal to t_0 of j+1
By assumption \ref{as:nonempty} $\mathcal{SS}^0$ is a non-empty set. From Eq. \eqref{eq:transCond} follows that $\bm{x}_0^0=\bm{x}_0^1$. Therefore, at time $t=0$ of the first iteration the solution of the LMPC
\begin{align}
&[\bm{x}_0^0,...,\bm{x}_N^0]\in\mathcal{SS}^{j-1}=\mathcal{SS}^0\\
&[\bm{u}_0^0,...,\bm{u}_{N-1}^0]
\end{align}
satisfies input and state constraints and is a feasible solution to \eqref{eq:generalLMPC}.

Now assume that the LMPC is feasible at time $t$ and let $\bm{x}_{t:t+N|t}^{*,j}$ and $\bm{u}_{t:t+N-1|t}^{*,j}$ be the optimal trajectory and the input sequence. As the state updates in \eqref{eq:systemDynamics} and \eqref{eq:LMPCupdate} are assumed to be identical we have $\bm{x}_{t+1}^j=\bm{x}_{t+1|t}^{*,j}$.
Also, the terminal constraint enforces $\bm{x}^{*,j}_{t+N|t} \in \mathcal{SS}^{j-1}$ and, from 
\begin{equation}\label{eq:OptimalIndex}
Q^{j-1}(\bm{x}_{t+N|t}^{*,j}) = J^{i^*}_{t^*\rightarrow \infty}(\bm{x}_{t+N|t}^{*,j}) = \sum\limits_{k=t^*}^{\infty} h(\bm{x}_k^{i^*},\bm{u}_k^{i^*}).
\end{equation}
where $\bm{x}_{t^*}^{i^*}=\bm{x}_{t+N|t}^{*,j}$, with $(i^*, t^*)$ being the minimizer in (\ref{eq:Qfunction}).
At time $t+1$ of iteration $j$ the input sequence
\begin{equation}\label{eq:newInput}
[\bm{u}_{t+1|t}^{*,j},\bm{u}_{t+2|t}^{*,j},...\bm{u}_{t+N-1|t}^{*,j},\bm{u}_{t^*}^{i*}]
\end{equation}
and the related state trajectory
\begin{equation}\label{eq:newTraj}
[\bm{x}_{t+1|t}^{*,j},\bm{x}_{t+2|t}^{*,j},...\bm{x}_{t+N-1|t}^{*,j},\bm{x}_{t^*}^{i^*},\bm{x}_{t^*+1}^{i^*}]
\end{equation}
satisfy input and state constraints. Therefore, \eqref{eq:newInput}-\eqref{eq:newTraj} is a feasible solution for the LMPC \eqref{eq:generalLMPC} at time $t+1$.

Now consider the final time step $\bar t_j$ of an iteration $j$. Assume that at time $\bar{t}_j$ of the $j$-th iteration the LMPC is feasible and let
\begin{align}\label{eq:newSol}
{\bf{u}}^{*,j}_{\bar{t}_j:\bar{t}_j+N|\bar{t}_j}  &= [\bm{u}_{\bar{t}_j|\bar{t}_j}^{*,j}, \cdots, \bm{u}_{\bar{t}_j+N-1|\bar{t}_j}^{*,j}]\\
{\bf{x}}^{*,j}_{\bar{t}_j:\bar{t}_j+N|\bar{t}_j} &= [\bm{x}_{\bar{t}_j|\bar{t}_j}^{*,j}, \cdots, \bm{x}_{\bar{t}_j+N|\bar{t}_j}^{*,j}]
\end{align}
be the optimal solution. By definition \eqref{eq:transCond} the system reaches the terminal invariant set at time $\bar t_j+1$ and the following iteration $j+1$ starts. We construct a feasible solution to the LMPC at time $t=0$ in iteration $j+1$ using \eqref{eq:newSol}.
Due to identical state updates we have
\begin{equation}
	\bm{x}^{j+1}_0 = \bm{x}_{\bar{t}_j+1}^j - \bm{p}= \bm{x}^{*,j}_{\bar{t}_j+1|\bar{t}_j} -\bm{p}.
\end{equation}
By the definition of $\bar t_j$ we have $\bm{x}_{\bar t_j+N}^{*,j}\in \mathcal{X}_F \subset \mathcal{SS}^{j-1}$ and therefore it exists $k\geq 0$ such that
\begin{equation}
\bm{x}_{\bar t_j+N|\bar t_j}^{*,j}=\bm{x}_{t^*}^{i^*} = \bm{x}_{\bar t_j+k+1}^{i^*}
\end{equation}
where $(i^*,t^*)$ are the minimizer in \eqref{eq:Qfunction} with $i^*<j$.

Moreover, we notice that
\begin{equation}
\bm{x}_{\bar{t}_j+N|\bar{t}_j}^{*,j}-\bm{p}=\bm{x}^{i^*}_{k+\bar{t}_j +1 }- \bm{p} = \bm{x}^{i^*+1}_k \in \mathcal{SS}^{i^*+1} \subset \mathcal{SS}^j.
\end{equation}
Since $\bm{x}_{k+1}^{i^*+1}\in\mathcal{SS}^j$, the trajectory
\begin{equation}\label{eq:finalTraj}
[\bm{x}_{\bar{t}_j+1|\bar{t}_j}^{*,j}- \bm{p}, \cdots, \bm{x}_{\bar{t}_j+N|\bar{t}_j}^{*,j}- \bm{p} = \bm{x}^{i^*+1}_k, \bm{x}^{i^*+1}_{k+1}]
\end{equation}
is a feasible trajectory for the LMPC \eqref{eq:generalLMPC}. Therefore, \eqref{eq:finalTraj} and the related input sequence is a feasible solution to the LMPC at time $t$ in iteration $j+1$.
\end{proof}

\begin{theorem}
Consider system \eqref{eq:systemDynamics} in closed loop with the LMPC controller \eqref{eq:generalLMPC} and \eqref{eq:recHorizon}. Let $\mathcal{SS}^j$ be the sampled safe set at iteration $j$. Let assumptions \ref{as:nonempty}-\ref{as:nonincLMPC} hold, then the iteration cost $J_{0\rightarrow\infty}^j(\cdot)$ does not increase with iteration index $j$.
\end{theorem}

\begin{proof}
First, we find a lower bound on the $j$-th iteration cost $J_{0\rightarrow \infty}^{j}(\cdot), ~\forall ~j>0$. Consider the realized state and input sequence in iteration $j$ which collects the first element of the optimal state and input sequence to the LMPC at time $t$, $~\forall t \in \mathbb{Z}_{0+}$.
By the definition of the iteration cost in \eqref{eq:iterationCost} and from assumption \ref{as:nonincLMPC}, we have
\begin{equation}
\begin{aligned}
J_{0\rightarrow \infty}^{j-1}(\bm{x}_0) &= \sum\limits_{t=0}^{\infty} h(\bm{x}_t^{j-1},\bm{u}_t^{j-1}) = \\
&=\sum\limits_{t=0}^{N-1} h(\bm{x}_t^{j-1},\bm{u}_t^{j-1}) + \sum\limits_{t=N}^{\infty} h(\bm{x}_t^{j-1},\bm{u}_t^{j-1}) \geq \\
&\geq \sum\limits_{t=0}^{N-1} h(\bm{x}_t^{j-1},\bm{u}_t^{j-1}) + Q^{j-1}(\bm{x}_N^{j-1}) \geq \\
&\geq \min_{\bm{u}_0,\ldots,\bm{u}_{N-1}} \left[ \sum_{k=0}^{N-1}  h(\bm{x}_k,\bm{u}_k) + Q^{j-1}(\bm{x}_N) \right] = \\
&= J_{0\rightarrow N}^{\scalebox{0.4}{LMPC},j}(\bm{x}_0^{j-1})\geq J_{0\rightarrow N}^{\scalebox{0.4}{LMPC},j}(\bm{x}_0^{j}).
\end{aligned}
\end{equation}
Given the above expression the proof follows from \mbox{\textit{Theorem 2}} in \cite{Rosolia2016}. 
\end{proof}

\begin{theorem}
Consider system \eqref{eq:systemDynamics} in closed loop with the LMPC controller.
	Let $\mathcal{SS}^j$ be the sampled safe set in iteration $j$. Let assumption \ref{as:nonempty} hold and assume that the closed loop system \eqref{eq:systemDynamics} and \eqref{eq:generalLMPC} converges to a steady state trajectory ${\bf{x}}^\infty$, for iteration $j\rightarrow \infty$. Then, the steady state input ${\bf{u}}^\infty = \lim_{j \to \infty} {\bf{u}}^j$ and the related steady state trajectory ${\bf{x}}^\infty = \lim_{j \to \infty} {\bf{x}}^j$ is a local optimal solution for the infinite horizon optimal control problem \eqref{eq:generalProblem}, i.e., ${\bf{x}}^\infty = {\bf{x}}^{*}$ and ${\bf{u}}^\infty = {\bf{u}}^{*}$.
\end{theorem}

\begin{proof}
The proof follows as in the LMPC for iterative tasks \cite{Rosolia2016}. 
\end{proof}

\subsection{Analysis and discussion of the proposed method}
The previous section extended the LMPC strategy from \cite{Rosolia2016} for batch processes to repetitive processes. This extension allows smooth transitions between iterations. Additionally, it does not require equal initial states for each iteration. Instead, the initial state of an iteration $j$ matches the final state of the previous iteration $j-1$.\\
Under the assumption of no model mismatch the proposed method is recursively feasible, stable, and it converges to an optimal solution. In general, the method can be applied to various repetitive systems. However, assumption \ref{as:nonincLMPC} has to be verified individually in order to guarantee non-increasing cost.

% Explain concept of going to 2*P
% Define J (not to infinity but only to P)
% Define stacked Q and the two areas (< P and >P)
% Prove feasibility
% Show and discuss stability/non increasing cost