\chapter{Introduction}
\section{Background and Motivation}
In almost every country and every industry we can see a steady increase and quest for automation today. Sales of industrial robots have more than doubled over the past six years, according to statistics of the International Federation of Robotics \cite{IFR2016}. This is just another evidence of the increasing automation of industry - apart from more public fields such as autonomously driving cars. Today, robots are used for all kinds of tasks, whereas many of these tasks can be characterized as being repetitive, meaning they are designed to repeat the same process over and over again. In order to save costs, time, or other resources, the execution of these tasks often has to be optimized over certain criteria. In complex automation tasks, however, it might be difficult to find a trajectory that optimizes the given process.

This is due to multiple reasons: Finding an optimal trajectory mostly implies minimizing or maximizing an objective function. Solving this optimization problem might prove to be difficult or infeasible for highly complex systems or long time horizons. Additionally, it might not be possible to find an exact mathematical description of the system.
% {\bfseries{Yes, but why? Here need to do a literature review and state why it is difficult (TIPS: Can we optimize a nonlinear system over a very long horizon? Let's assume that we can: How about we do not know the system dynamics? Can we compute an optimal trajectory in that case? This may motivate why you want to learn the trajectory and the dynamics at the same time and you do not want to run a big optimization off line (assuming that you can run that optimization off line))}}. \\
In order to tackle this problem of optimizing complex system trajectories, previous research has already focused on iteratively improving trajectories. Some methods like the class of Iterative Learning Controls (ILC, \cite{Lee2007}, \cite{Bristow2006}) try to find optimal control inputs based on a given reference trajectory. A novel method, called Learning Model Predictive Control (LMPC, \cite{Rosolia2016}), allows finding optimal trajectories without requiring a given reference trajectory.

The work from \cite{Rosolia2016} can be applied on a large class of so-called batch processes. These are characterized by starting each iteration from the same initial state. In this work, we would like to extend this theory to continuous tasks; these feature smooth transitions between iterations and therefore do not require equal initial conditions.

%{\bfseries{The next two paragraph are too detailed, imagine someone that has never seen the LMPC reads it. Also, assume that the reader is not familiar with repetitive/iterative tasks i.e. explain what is a batch and cite (Good survey paper by A. Alleyne)}}
%Previous research like Iterative Learning Control (ILC, \cite{Lee2007}, \cite{Bristow2006}) or Learning Model Predictive Control (LMPC, \cite{Rosolia2016}) has already focused on improving trajectories over many iterations.\\
%As opposed to ILC, the theory of LMPC allows finding an optimal, reference-free trajectory, given a general optimization function. However, so far it has only been tested for batch processes, which start every iteration at the same initial state.\\
%We are now interested in extending this theory to continuous repetitive tasks which are characterized by a smooth transition between iterations, abolishing the need for same initial conditions.
An example application of improving continuous repetitive tasks is the race driving problem, in which the goal is to minimize the lap time while always starting a new lap from where the previous lap ended. We would like to use this scenario to test the performance of the LMPC on a continuous repetitive system.

%\begin{itemize}
%\item Increasing use and development of industrial robots over recent years, for production automation in low-wage countries, in metal, electrical, automotive industries, due to higher demand and also progress in research and the need possibilities to make everything even more efficient and automatic (automation).
%\item Repetitive tasks: industrial robots - batch processes
%\item Demand for efficient performance in different regards - energy (environment), time and energy cost (economical)
%\item Application mainly in fabrication, chemistry, biochemistry
%\item Increasing complexity of systems
%\item Increasing use of robots for repetitive tasks
%\item MPC because we can include input and state constraints
%\item Previous work: Mainly ILC and RC. Already work on MPC in RC tasks with $x_F$=$x_0$. But always only (periodic) reference tracking/rejection on fixed length iterations. Reference is always given and optimal input is calculated.
%\item Categorization/definition of iterative, repetitive processes/batch processes
%\item Previous work of Ugo: ILMPC on batch processes
%\item Now this work: RLMPC on continuous processes
%\item \cite{Wang2009} makes a good categorization of different types of processes: He distinguishes between batch processes and continuous processes. Batch processes are intermittently run as opposed to continuous processes which are continuous even through transitions of runs.
%\item This thesis: Application on race driving
%\item Lots of previous research in race driving
%\item Previous work: Autonomous racing using MPCC applied on 1:43 cars \cite{Liniger2015}
%\end{itemize}

\section{Problem description, previous work, and goal}
Based on \cite{Rosolia2016}, we would like to develop a control strategy for repetitive systems that learns from previous iterations in order to improve its performance. The performance should be determined by an objective function which is defined according to the given problem. This strategy should be applicable for continuous repetitive systems with smooth transitions, meaning that a new iteration begins at the final state of the previous iteration.
%{\bfseries{Write about extension of existing LMPC? And about combination with system identification.}}
%{\bfseries{No, this statement is too strong...remember people are always critical. You cannot state that you have an efficient method for solving infinite time optimal control problem...basically is means that you have an efficient method to solve partial differential equations which is an open problem...people are working on it since ever. You can state that the goal is to build a learning controller that can learn from experience and then are results you show that your controller computes the optimal trajectory}}. {\bfseries{OK, I noticed that you have not conclude the section. i would keep theory and examples separate. You have a contribution you thesis is not just applying the LMPC to autonomous racing it is actually extending its range of applicability AND testing it. Make sure you underline both things}}

We want to combine this control scheme with an online system identification method. This would allow reacting to unknown or changing system dynamics.

Finally, we want to show the practicability of this method in the race driving scenario in simulation and then apply it on a 1:10 scale remote-controlled race car. For that, we need to develop a technique that estimates all necessary states of the systems, using a low-cost system that is fast and easy to set up.

All these tasks have to be computational efficient so that we can perform experiments in real time, driving the car at high velocities.

There has been research on finding the optimal time trajectory through a given race track, an overview can be found in \cite{Sharp2011}. Mostly, the goal is to find efficient ways of solving the complex optimization problem by making specific assumptions.

As an example, in \cite{Liniger2015} two approaches are presented. The first one consists of a two-level MPC controller, in which the high-level MPC computes a path while the low-level MPC provides the path tracking. The second approach uses contouring control to combine both tasks in one MPC.

In \cite{Rucco2015} the authors transform the general race driving problem into an unconstrained problem which allows efficient computation of optimal solutions.

This thesis is organized as follows: In the second chapter, a short introduction to Model Predictive Control (MPC) and Learning Model Predictive Control (LMPC) is given. Based on that, an extension to repetitive systems (RLMPC) is presented. The third chapter introduces the formulation of car system dynamics, the application of RLMPC on race driving, and simulation results. The fourth chapter illustrates the control implementation on a 1:10 scale race car. Experiments show the real-time feasibility of the proposed control strategy. Finally, the fifth chapter provides conclusions and final remarks.
%\begin{itemize}
%\item Develop an efficient method that finds the optimal trajectory in a repetitive system.
%\item Race driving means operating at the limits of its system dynamics
%\item Difficulty: Estimate lateral dynamics using low cost/high noise sensors
%\item LMPC only valid for no model mismatch, so also identify the model dynamics in real time
%\item Find out what defines repetitive systems
%\item Test this framework on an autonomous car
%\item Applied system: Race driving
%\item Implementation on small RC car
%\item Previous work: LMPC on iterative tasks
%\item End of this section: How this paper is organized...
%\end{itemize}
